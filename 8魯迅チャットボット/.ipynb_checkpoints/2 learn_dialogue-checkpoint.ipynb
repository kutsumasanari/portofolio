{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17936,
     "status": "ok",
     "timestamp": 1670159788452,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "4rNVz4J_R3VP",
    "outputId": "17b8dabb-7a2b-4f61-d878-59818a241a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/gdrive/MyDrive/8 魯迅チャットボット/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc2puvMNOaVK"
   },
   "source": [
    "# 対話の学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk3LX0ILOaVP"
   },
   "source": [
    "## １使用する文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1670159789396,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "0A4fVzCUOaVQ",
    "outputId": "3532ea43-49e2-406e-e8d5-cbe6f8130dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', '!', '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'C', 'M', 'N', 'O', 'P', 'Q', 'a', 'd', 'e', 'f', 'h', 'i', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'y', '×', '―', '○', '、', '。', '々', '〆', '〇', 'ぁ', 'あ', 'ぃ', 'い', 'ぅ', 'う', 'ぇ', 'え', 'ぉ', 'お', 'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご', 'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ', 'た', 'だ', 'ち', 'ぢ', 'っ', 'つ', 'づ', 'て', 'で', 'と', 'ど', 'な', 'に', 'ぬ', 'ね', 'の', 'は', 'ば', 'ぱ', 'ひ', 'び', 'ぴ', 'ふ', 'ぶ', 'ぷ', 'へ', 'べ', 'ぺ', 'ほ', 'ぼ', 'ぽ', 'ま', 'み', 'む', 'め', 'も', 'ゃ', 'や', 'ゅ', 'ゆ', 'ょ', 'よ', 'ら', 'り', 'る', 'れ', 'ろ', 'ゎ', 'わ', 'ゐ', 'ゑ', 'を', 'ん', 'ゝ', 'ゞ', 'ァ', 'ア', 'ィ', 'イ', 'ゥ', 'ウ', 'ェ', 'エ', 'ォ', 'オ', 'カ', 'ガ', 'キ', 'ギ', 'ク', 'グ', 'ケ', 'ゲ', 'コ', 'ゴ', 'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ゼ', 'ソ', 'ゾ', 'タ', 'ダ', 'チ', 'ヂ', 'ッ', 'ツ', 'ヅ', 'テ', 'デ', 'ト', 'ド', 'ナ', 'ニ', 'ヌ', 'ネ', 'ノ', 'ハ', 'バ', 'パ', 'ヒ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ベ', 'ペ', 'ホ', 'ボ', 'ポ', 'マ', 'ミ', 'ム', 'メ', 'モ', 'ャ', 'ヤ', 'ュ', 'ユ', 'ョ', 'ヨ', 'ラ', 'リ', 'ル', 'レ', 'ロ', 'ヮ', 'ワ', 'ヰ', 'ヱ', 'ヲ', 'ン', 'ヴ', 'ー', '！', '＋', '／', '＜', '？', 'Ａ', 'Ｄ', 'Ｋ', 'Ｎ', 'Ｏ', 'Ｑ', 'Ｓ']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "hiragana = \"ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞ\\\n",
    "ただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽ\\\n",
    "まみむめもゃやゅゆょよらりるれろゎわゐゑをん\"\n",
    "\n",
    "katakana = \"ァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾ\\\n",
    "タダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポ\\\n",
    "マミムメモャヤュユョヨラリルレロヮワヰヱヲンヴ\"\n",
    "\n",
    "chars = hiragana + katakana\n",
    "\n",
    "with open(\"kana_rojin.txt\", mode=\"r\", encoding=\"utf-8\") as f: \n",
    "    text = f.read()\n",
    "    \n",
    "for char in text:  # ひらがな、カタカナ以外でコーパスに使われている文字を追加\n",
    "    if char not in chars:\n",
    "        chars += char\n",
    "        \n",
    "chars += \"\\t\\n\"  # タブと改行を追加\n",
    "        \n",
    "chars_list = sorted(list(chars))  # 文字列をリストに変換してソートする\n",
    "print(chars_list)\n",
    "\n",
    "with open(\"kana_chars.pickle\", mode=\"wb\") as f:  # pickleで保存\n",
    "    pickle.dump(chars_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyqcmCprOaVT"
   },
   "source": [
    "## ２文字のベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1670159790067,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "S52SPBCPOaVU",
    "outputId": "60a5facb-c3bb-4d4b-bd87-41ce7aa811c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-73e6e01929f6>:30: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_encoder = np.zeros((n_sample, max_length_x, n_char), dtype=np.bool)  # encoderへの入力\n",
      "<ipython-input-4-73e6e01929f6>:31: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_decoder = np.zeros((n_sample, max_length_t, n_char), dtype=np.bool)  # decoderへの入力\n",
      "<ipython-input-4-73e6e01929f6>:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  t_decoder = np.zeros((n_sample, max_length_t, n_char), dtype=np.bool)  # decoderの正解\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3124, 128, 230)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# インデックスと文字で辞書を作成\n",
    "char_indices = {}  # 文字がキーでインデックスが値\n",
    "for i, char in enumerate(chars_list):\n",
    "    char_indices[char] = i\n",
    "indices_char = {}  # インデックスがキーで文字が値\n",
    "for i, char in enumerate(chars_list):\n",
    "    indices_char[i] = char\n",
    "    \n",
    "seperator = \"。\"\n",
    "sentence_list = text.split(seperator) \n",
    "sentence_list.pop() \n",
    "sentence_list = [x+seperator for x in sentence_list]\n",
    "\n",
    "max_sentence_length = 128  # 文章の最大長さ。これより長い文章はカットされる。\n",
    "sentence_list = [sentence for sentence in sentence_list if len(sentence) <= max_sentence_length]  # 長すぎる文章のカット\n",
    "\n",
    "n_char = len(chars_list)  # 文字の種類の数\n",
    "n_sample = len(sentence_list) - 1  # サンプル数\n",
    "\n",
    "x_sentences = []  # 入力の文章\n",
    "t_sentences = []  # 正解の文章\n",
    "for i in range(n_sample):\n",
    "    x_sentences.append(sentence_list[i])\n",
    "    t_sentences.append(\"\\t\" + sentence_list[i+1] + \"\\n\")  # 正解は先頭にタブ、末尾に改行を加える\n",
    "max_length_x = max_sentence_length  # 入力文章の最大長さ\n",
    "max_length_t = max_sentence_length + 2  # 正解文章の最大長さ\n",
    "\n",
    "x_encoder = np.zeros((n_sample, max_length_x, n_char), dtype=np.bool)  # encoderへの入力\n",
    "x_decoder = np.zeros((n_sample, max_length_t, n_char), dtype=np.bool)  # decoderへの入力\n",
    "t_decoder = np.zeros((n_sample, max_length_t, n_char), dtype=np.bool)  # decoderの正解\n",
    "\n",
    "for i in range(n_sample):\n",
    "    x_sentence = x_sentences[i]\n",
    "    t_sentence = t_sentences[i]\n",
    "    for j, char in enumerate(x_sentence):\n",
    "        x_encoder[i, j, char_indices[char]] = 1  # encoderへの入力をone-hot表現で表す\n",
    "    for j, char in enumerate(t_sentence):\n",
    "        x_decoder[i, j, char_indices[char]] = 1  # decoderへの入力をone-hot表現で表す\n",
    "        if j > 0:  # 正解は入力より1つ前の時刻のものにする\n",
    "            t_decoder[i, j-1, char_indices[char]] = 1\n",
    "            \n",
    "print(x_encoder.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42dbtSBNOaVV"
   },
   "source": [
    "## ３各設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670159790070,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "ka4UrYLnOaVV"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 1000\n",
    "n_mid = 256  # 中間層のニューロン数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OXLIusuOaVW"
   },
   "source": [
    "## ４学習用モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4623,
     "status": "ok",
     "timestamp": 1670159794685,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "1CuYqWbAOaVX",
    "outputId": "04116a22-bd7f-4396-fd51-bc5f088ee393"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 230)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 230)]  0           []                               \n",
      "                                                                                                  \n",
      " masking (Masking)              (None, None, 230)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " masking_1 (Masking)            (None, None, 230)    0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " gru (GRU)                      [(None, 256),        374784      ['masking[0][0]']                \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    [(None, None, 256),  374784      ['masking_1[0][0]',              \n",
      "                                 (None, 256)]                     'gru[0][1]']                    \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 230)    59110       ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 808,678\n",
      "Trainable params: 808,678\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, GRU, Input, Masking\n",
    "\n",
    "encoder_input = Input(shape=(None, n_char))\n",
    "encoder_mask = Masking(mask_value=0)  # 全ての要素が0であるベクトルの入力は無視する\n",
    "encoder_masked = encoder_mask(encoder_input)\n",
    "encoder_lstm = GRU(n_mid, dropout=0.2, recurrent_dropout=0.2, return_state=True)  # dropoutを設定し、ニューロンをランダムに無効にする\n",
    "encoder_output, encoder_state_h = encoder_lstm(encoder_masked)\n",
    "\n",
    "decoder_input = Input(shape=(None, n_char))\n",
    "decoder_mask = Masking(mask_value=0)  # 全ての要素が0であるベクトルの入力は無視する\n",
    "decoder_masked = decoder_mask(decoder_input)\n",
    "decoder_lstm = GRU(n_mid, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, return_state=True)  # dropoutを設定\n",
    "decoder_output, _ = decoder_lstm(decoder_masked, initial_state=encoder_state_h)  # encoderの状態を初期状態にする\n",
    "decoder_dense = Dense(n_char, activation='softmax')\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "model = Model([encoder_input, decoder_input], decoder_output)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-n8PUATOaVY"
   },
   "source": [
    "## ５学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gcQd5rCOaVZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "88/88 [==============================] - 84s 887ms/step - loss: 1.4306 - val_loss: 1.4413\n",
      "Epoch 2/1000\n",
      "88/88 [==============================] - 76s 870ms/step - loss: 1.3033 - val_loss: 1.3413\n",
      "Epoch 3/1000\n",
      "88/88 [==============================] - 78s 881ms/step - loss: 1.2422 - val_loss: 1.2972\n",
      "Epoch 4/1000\n",
      "88/88 [==============================] - 77s 873ms/step - loss: 1.2150 - val_loss: 1.2767\n",
      "Epoch 5/1000\n",
      "88/88 [==============================] - 78s 881ms/step - loss: 1.1961 - val_loss: 1.2581\n",
      "Epoch 6/1000\n",
      "88/88 [==============================] - 77s 871ms/step - loss: 1.1815 - val_loss: 1.2431\n",
      "Epoch 7/1000\n",
      "88/88 [==============================] - 76s 869ms/step - loss: 1.1701 - val_loss: 1.2359\n",
      "Epoch 8/1000\n",
      "88/88 [==============================] - 77s 877ms/step - loss: 1.1603 - val_loss: 1.2281\n",
      "Epoch 9/1000\n",
      "88/88 [==============================] - 76s 863ms/step - loss: 1.1528 - val_loss: 1.2213\n",
      "Epoch 10/1000\n",
      "88/88 [==============================] - 76s 858ms/step - loss: 1.1443 - val_loss: 1.2168\n",
      "Epoch 11/1000\n",
      "88/88 [==============================] - 77s 874ms/step - loss: 1.1375 - val_loss: 1.2087\n",
      "Epoch 12/1000\n",
      "88/88 [==============================] - 75s 855ms/step - loss: 1.1322 - val_loss: 1.2067\n",
      "Epoch 13/1000\n",
      "88/88 [==============================] - 77s 872ms/step - loss: 1.1251 - val_loss: 1.1989\n",
      "Epoch 14/1000\n",
      "88/88 [==============================] - 75s 852ms/step - loss: 1.1205 - val_loss: 1.1975\n",
      "Epoch 15/1000\n",
      "88/88 [==============================] - 74s 847ms/step - loss: 1.1151 - val_loss: 1.1920\n",
      "Epoch 16/1000\n",
      "88/88 [==============================] - 77s 869ms/step - loss: 1.1105 - val_loss: 1.1892\n",
      "Epoch 17/1000\n",
      "88/88 [==============================] - 75s 855ms/step - loss: 1.1038 - val_loss: 1.1802\n",
      "Epoch 18/1000\n",
      "88/88 [==============================] - 75s 847ms/step - loss: 1.0986 - val_loss: 1.1770\n",
      "Epoch 19/1000\n",
      "88/88 [==============================] - 75s 856ms/step - loss: 1.0927 - val_loss: 1.1738\n",
      "Epoch 20/1000\n",
      "88/88 [==============================] - 75s 853ms/step - loss: 1.0967 - val_loss: 1.1674\n",
      "Epoch 21/1000\n",
      "88/88 [==============================] - 75s 857ms/step - loss: 1.0839 - val_loss: 1.1667\n",
      "Epoch 22/1000\n",
      "88/88 [==============================] - 74s 846ms/step - loss: 1.0788 - val_loss: 1.1633\n",
      "Epoch 23/1000\n",
      "88/88 [==============================] - 74s 840ms/step - loss: 1.0738 - val_loss: 1.1588\n",
      "Epoch 24/1000\n",
      "88/88 [==============================] - 76s 864ms/step - loss: 1.0706 - val_loss: 1.1579\n",
      "Epoch 25/1000\n",
      "88/88 [==============================] - 74s 845ms/step - loss: 1.0646 - val_loss: 1.1530\n",
      "Epoch 26/1000\n",
      "88/88 [==============================] - 75s 850ms/step - loss: 1.0600 - val_loss: 1.1507\n",
      "Epoch 27/1000\n",
      "88/88 [==============================] - 76s 870ms/step - loss: 1.0539 - val_loss: 1.1471\n",
      "Epoch 28/1000\n",
      "88/88 [==============================] - 74s 839ms/step - loss: 1.0503 - val_loss: 1.1482\n",
      "Epoch 29/1000\n",
      "88/88 [==============================] - 73s 833ms/step - loss: 1.0449 - val_loss: 1.1409\n",
      "Epoch 30/1000\n",
      "88/88 [==============================] - 75s 856ms/step - loss: 1.0412 - val_loss: 1.1398\n",
      "Epoch 31/1000\n",
      "88/88 [==============================] - 74s 846ms/step - loss: 1.0366 - val_loss: 1.1347\n",
      "Epoch 32/1000\n",
      "88/88 [==============================] - 74s 839ms/step - loss: 1.0327 - val_loss: 1.1328\n",
      "Epoch 33/1000\n",
      "88/88 [==============================] - 75s 858ms/step - loss: 1.0266 - val_loss: 1.1310\n",
      "Epoch 34/1000\n",
      "88/88 [==============================] - 74s 837ms/step - loss: 1.0241 - val_loss: 1.1286\n",
      "Epoch 35/1000\n",
      "88/88 [==============================] - 74s 841ms/step - loss: 1.0210 - val_loss: 1.1261\n",
      "Epoch 36/1000\n",
      "88/88 [==============================] - 75s 851ms/step - loss: 1.0172 - val_loss: 1.1262\n",
      "Epoch 37/1000\n",
      "88/88 [==============================] - 75s 848ms/step - loss: 1.0120 - val_loss: 1.1221\n",
      "Epoch 38/1000\n",
      "88/88 [==============================] - 75s 855ms/step - loss: 1.0087 - val_loss: 1.1204\n",
      "Epoch 39/1000\n",
      "88/88 [==============================] - 74s 836ms/step - loss: 1.0050 - val_loss: 1.1209\n",
      "Epoch 40/1000\n",
      "88/88 [==============================] - 74s 836ms/step - loss: 1.0017 - val_loss: 1.1203\n",
      "Epoch 41/1000\n",
      "88/88 [==============================] - 75s 855ms/step - loss: 0.9982 - val_loss: 1.1189\n",
      "Epoch 42/1000\n",
      "88/88 [==============================] - 74s 838ms/step - loss: 0.9948 - val_loss: 1.1166\n",
      "Epoch 43/1000\n",
      "88/88 [==============================] - 74s 839ms/step - loss: 0.9909 - val_loss: 1.1171\n",
      "Epoch 44/1000\n",
      "88/88 [==============================] - 75s 858ms/step - loss: 0.9866 - val_loss: 1.1142\n",
      "Epoch 45/1000\n",
      "88/88 [==============================] - 74s 841ms/step - loss: 0.9851 - val_loss: 1.1136\n",
      "Epoch 46/1000\n",
      "88/88 [==============================] - 74s 842ms/step - loss: 0.9833 - val_loss: 1.1103\n",
      "Epoch 47/1000\n",
      "88/88 [==============================] - 76s 860ms/step - loss: 0.9794 - val_loss: 1.1110\n",
      "Epoch 48/1000\n",
      "88/88 [==============================] - 74s 837ms/step - loss: 0.9760 - val_loss: 1.1095\n",
      "Epoch 49/1000\n",
      "88/88 [==============================] - 74s 837ms/step - loss: 0.9738 - val_loss: 1.1078\n",
      "Epoch 50/1000\n",
      "88/88 [==============================] - 75s 852ms/step - loss: 0.9707 - val_loss: 1.1087\n",
      "Epoch 51/1000\n",
      "88/88 [==============================] - 74s 842ms/step - loss: 0.9682 - val_loss: 1.1069\n",
      "Epoch 52/1000\n",
      "88/88 [==============================] - 74s 843ms/step - loss: 0.9670 - val_loss: 1.1059\n",
      "Epoch 53/1000\n",
      "88/88 [==============================] - 74s 846ms/step - loss: 0.9631 - val_loss: 1.1077\n",
      "Epoch 54/1000\n",
      "88/88 [==============================] - 76s 860ms/step - loss: 0.9606 - val_loss: 1.1049\n",
      "Epoch 55/1000\n",
      "88/88 [==============================] - 74s 842ms/step - loss: 0.9588 - val_loss: 1.1079\n",
      "Epoch 56/1000\n",
      "88/88 [==============================] - 74s 838ms/step - loss: 0.9565 - val_loss: 1.1039\n",
      "Epoch 57/1000\n",
      "88/88 [==============================] - 75s 858ms/step - loss: 0.9524 - val_loss: 1.1038\n",
      "Epoch 58/1000\n",
      "88/88 [==============================] - 74s 839ms/step - loss: 0.9518 - val_loss: 1.1035\n",
      "Epoch 59/1000\n",
      "88/88 [==============================] - 74s 838ms/step - loss: 0.9499 - val_loss: 1.1019\n",
      "Epoch 60/1000\n",
      "88/88 [==============================] - 75s 856ms/step - loss: 0.9462 - val_loss: 1.1055\n",
      "Epoch 61/1000\n",
      "88/88 [==============================] - 74s 841ms/step - loss: 0.9445 - val_loss: 1.1055\n",
      "Epoch 62/1000\n",
      "88/88 [==============================] - 74s 840ms/step - loss: 0.9418 - val_loss: 1.1030\n",
      "Epoch 63/1000\n",
      "88/88 [==============================] - 74s 843ms/step - loss: 0.9390 - val_loss: 1.1024\n",
      "Epoch 64/1000\n",
      "88/88 [==============================] - 76s 859ms/step - loss: 0.9377 - val_loss: 1.1017\n",
      "Epoch 65/1000\n",
      "88/88 [==============================] - 74s 839ms/step - loss: 0.9353 - val_loss: 1.1020\n",
      "Epoch 66/1000\n",
      "88/88 [==============================] - 74s 841ms/step - loss: 0.9334 - val_loss: 1.1030\n",
      "Epoch 67/1000\n",
      "88/88 [==============================] - 75s 852ms/step - loss: 0.9317 - val_loss: 1.1008\n",
      "Epoch 68/1000\n",
      "88/88 [==============================] - 75s 857ms/step - loss: 0.9298 - val_loss: 1.1019\n",
      "Epoch 69/1000\n",
      "88/88 [==============================] - 74s 839ms/step - loss: 0.9275 - val_loss: 1.1015\n",
      "Epoch 70/1000\n",
      "88/88 [==============================] - 73s 833ms/step - loss: 0.9261 - val_loss: 1.1021\n",
      "Epoch 71/1000\n",
      "88/88 [==============================] - 73s 825ms/step - loss: 0.9250 - val_loss: 1.1014\n",
      "Epoch 72/1000\n",
      "88/88 [==============================] - 74s 837ms/step - loss: 0.9234 - val_loss: 1.1030\n",
      "Epoch 73/1000\n",
      "88/88 [==============================] - 73s 835ms/step - loss: 0.9202 - val_loss: 1.1013\n",
      "Epoch 74/1000\n",
      "88/88 [==============================] - 73s 834ms/step - loss: 0.9196 - val_loss: 1.1005\n",
      "Epoch 75/1000\n",
      "88/88 [==============================] - 73s 833ms/step - loss: 0.9156 - val_loss: 1.1013\n",
      "Epoch 76/1000\n",
      "88/88 [==============================] - 74s 835ms/step - loss: 0.9159 - val_loss: 1.1006\n",
      "Epoch 77/1000\n",
      "88/88 [==============================] - 75s 849ms/step - loss: 0.9141 - val_loss: 1.0999\n",
      "Epoch 78/1000\n",
      "88/88 [==============================] - 74s 840ms/step - loss: 0.9119 - val_loss: 1.1029\n",
      "Epoch 79/1000\n",
      "88/88 [==============================] - 75s 849ms/step - loss: 0.9120 - val_loss: 1.1009\n",
      "Epoch 80/1000\n",
      "88/88 [==============================] - 73s 833ms/step - loss: 0.9087 - val_loss: 1.1006\n",
      "Epoch 81/1000\n",
      "88/88 [==============================] - 74s 839ms/step - loss: 0.9084 - val_loss: 1.1014\n",
      "Epoch 82/1000\n",
      "88/88 [==============================] - 73s 834ms/step - loss: 0.9049 - val_loss: 1.1017\n",
      "Epoch 83/1000\n",
      "88/88 [==============================] - 75s 854ms/step - loss: 0.9049 - val_loss: 1.1006\n",
      "Epoch 84/1000\n",
      "88/88 [==============================] - 74s 838ms/step - loss: 0.9035 - val_loss: 1.1034\n",
      "Epoch 85/1000\n",
      "88/88 [==============================] - 74s 843ms/step - loss: 0.8997 - val_loss: 1.1016\n",
      "Epoch 86/1000\n",
      "88/88 [==============================] - 73s 835ms/step - loss: 0.8995 - val_loss: 1.1030\n",
      "Epoch 87/1000\n",
      "88/88 [==============================] - 75s 850ms/step - loss: 0.8990 - val_loss: 1.1025\n",
      "Epoch 88/1000\n",
      "88/88 [==============================] - 74s 836ms/step - loss: 0.8974 - val_loss: 1.1013\n",
      "Epoch 89/1000\n",
      "88/88 [==============================] - 74s 838ms/step - loss: 0.8961 - val_loss: 1.1054\n",
      "Epoch 90/1000\n",
      "88/88 [==============================] - 73s 830ms/step - loss: 0.8952 - val_loss: 1.1043\n",
      "Epoch 91/1000\n",
      "88/88 [==============================] - 74s 842ms/step - loss: 0.8932 - val_loss: 1.1047\n",
      "Epoch 92/1000\n",
      "88/88 [==============================] - 73s 829ms/step - loss: 0.8908 - val_loss: 1.1020\n",
      "Epoch 93/1000\n",
      "88/88 [==============================] - 73s 829ms/step - loss: 0.8909 - val_loss: 1.1044\n",
      "Epoch 94/1000\n",
      "88/88 [==============================] - 73s 829ms/step - loss: 0.8898 - val_loss: 1.1027\n",
      "Epoch 95/1000\n",
      "88/88 [==============================] - 75s 850ms/step - loss: 0.8873 - val_loss: 1.1059\n",
      "Epoch 96/1000\n",
      "88/88 [==============================] - 73s 832ms/step - loss: 0.8862 - val_loss: 1.1052\n",
      "Epoch 97/1000\n",
      "88/88 [==============================] - 73s 826ms/step - loss: 0.8859 - val_loss: 1.1096\n",
      "Epoch 98/1000\n",
      "88/88 [==============================] - 73s 830ms/step - loss: 0.8839 - val_loss: 1.1054\n",
      "Epoch 99/1000\n",
      "88/88 [==============================] - 74s 845ms/step - loss: 0.8827 - val_loss: 1.1058\n",
      "Epoch 100/1000\n",
      "88/88 [==============================] - 73s 831ms/step - loss: 0.8829 - val_loss: 1.1046\n",
      "Epoch 101/1000\n",
      "88/88 [==============================] - 73s 834ms/step - loss: 0.8811 - val_loss: 1.1054\n",
      "Epoch 102/1000\n",
      "88/88 [==============================] - 74s 843ms/step - loss: 0.8792 - val_loss: 1.1063\n",
      "Epoch 103/1000\n",
      "88/88 [==============================] - 75s 853ms/step - loss: 0.8790 - val_loss: 1.1066\n",
      "Epoch 104/1000\n",
      "88/88 [==============================] - 74s 845ms/step - loss: 0.8770 - val_loss: 1.1064\n",
      "Epoch 105/1000\n",
      "88/88 [==============================] - 73s 833ms/step - loss: 0.8772 - val_loss: 1.1083\n",
      "Epoch 106/1000\n",
      "88/88 [==============================] - 74s 842ms/step - loss: 0.8749 - val_loss: 1.1103\n",
      "Epoch 107/1000\n",
      "88/88 [==============================] - 75s 854ms/step - loss: 0.8744 - val_loss: 1.1079\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "# val_lossに改善が見られなくなってから、30エポックで学習は終了\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=30) \n",
    "\n",
    "history = model.fit([x_encoder, x_decoder], t_decoder,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     validation_split=0.1,  # 10%は検証用\n",
    "                     callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZI0G3iLWOaVZ"
   },
   "source": [
    "## ６学習の推移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Ku5PVZtJOaVa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(np.arange(len(loss)), loss)\n",
    "plt.plot(np.arange(len(val_loss)), val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0JKTbhvOaVb"
   },
   "source": [
    "## ７予測用モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9xCMj_vDOaVb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# encoderのモデル\n",
    "encoder_model = Model(encoder_input, encoder_state_h)\n",
    "\n",
    "# decoderのモデル\n",
    "decoder_state_in_h = Input(shape=(n_mid,))\n",
    "decoder_state_in = [decoder_state_in_h]\n",
    "\n",
    "decoder_output, decoder_state_h = decoder_lstm(decoder_input,\n",
    "                                               initial_state=decoder_state_in_h)\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "decoder_model = Model([decoder_input] + decoder_state_in,\n",
    "                      [decoder_output, decoder_state_h])\n",
    "\n",
    "# モデルの保存\n",
    "encoder_model.save('encoder_model.h5')\n",
    "decoder_model.save('decoder_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tx0rZPaWOaVd"
   },
   "source": [
    "## ８返答作成用の関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JZAzAmfXOaVd"
   },
   "outputs": [],
   "source": [
    "def respond(input_data, beta=5):\n",
    "    state_value = encoder_model.predict(input_data)\n",
    "    y_decoder = np.zeros((1, 1, n_char))  # decoderの出力を格納する配列\n",
    "    y_decoder[0][0][char_indices[\"\\t\"]] = 1  # decoderの最初の入力はタブ。one-hot表現にする。\n",
    "\n",
    "    respond_sentence = \"\"  # 返答の文字列\n",
    "    while True:\n",
    "        y, h = decoder_model.predict([y_decoder, state_value])\n",
    "        p_power = y[0][0] ** beta  # 確率分布の調整\n",
    "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power)) \n",
    "        next_char = indices_char[next_index]  # 次の文字\n",
    "\n",
    "        if (next_char == \"\\n\" or len(respond_sentence) >= max_length_x):\n",
    "            break  # 次の文字が改行のとき、もしくは最大文字数を超えたときは終了\n",
    "            \n",
    "        respond_sentence += next_char\n",
    "        y_decoder = np.zeros((1, 1, n_char))  # 次の時刻の入力\n",
    "        y_decoder[0][0][next_index] = 1\n",
    "\n",
    "        state_value = h  # 次の時刻の状態\n",
    "\n",
    "    return respond_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v77U5wUDOaVe"
   },
   "source": [
    "## ９動作の確認\n",
    "訓練データの最初の100文を使って、どのような返答が返ってくるかを確かめる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-rhzGkQOaVe"
   },
   "outputs": [],
   "source": [
    "for i in range(100):  \n",
    "    x_in = x_encoder[i:i+1]  # 入力\n",
    "    responce = respond(x_in)  # 返答\n",
    "    print(\"Input:\", x_sentences[i])\n",
    "    print(\"Response:\", responce)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "",
   "version": ""
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
