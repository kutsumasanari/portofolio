{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yukinaga/image_generation/blob/main/section_5/02_image_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K74mqS_L8nq4"
   },
   "source": [
    "# LSGANによる画像素材の生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TzTU3cUSp4_"
   },
   "source": [
    "## １データの読み込み\n",
    "ImageNetから、ウサギ画像をダウンロードし、アップロードする。  \n",
    "https://image-net.org/data/winter21_whole/n02325366.tar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1668671015528,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "a577xgPggdMi",
    "outputId": "a20c6921-49e1-49c3-c622-fcd2d4cf27b6"
   },
   "outputs": [],
   "source": [
    "rabbit_image_path = '/content/gdrive/MyDrive/rabbit_image_generation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7h50pYSRaZ0"
   },
   "source": [
    "## ２各設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1668671020839,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "Xc9WCis8TGwx",
    "outputId": "f950a5db-b589-4cf3-e8c7-23ebaf02169e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "img_size = 128  # 入力画像の高さと幅\n",
    "n_noise = 64  # ノイズの数\n",
    "\n",
    "epochs = 1200 # 学習回数\n",
    "interval = 20  # 経過の表示間隔\n",
    "batch_size = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(256),  # 画像の中央を取り出し\n",
    "    transforms.RandomCrop(196),  # ランダムに切り抜き\n",
    "    transforms.Resize((img_size, img_size)),  # サイズの変更\n",
    "    transforms.RandomHorizontalFlip(),  # ランダムに左右反転\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # -1から1の範囲に\n",
    "])\n",
    "\n",
    "# データセットの設定\n",
    "pets_datasets = datasets.ImageFolder(\n",
    "    root= rabbit_image_path, \n",
    "    transform=transform\n",
    "    )\n",
    "print(\"画像の枚数:\", len(pets_datasets))\n",
    "\n",
    "# DataLoaderの設定\n",
    "train_loader = DataLoader(pets_datasets, \n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                           num_workers=2\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPdix5iqTntg"
   },
   "source": [
    "## ３画像データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "executionInfo": {
     "elapsed": 27939,
     "status": "ok",
     "timestamp": 1668671058032,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "YgIQOsQZI2ab",
    "outputId": "7fd0b4af-448f-4c33-91ee-962fc4d34b4b"
   },
   "outputs": [],
   "source": [
    "image = iter(train_loader).next()[0]\n",
    "image = image.cpu().detach().numpy().transpose(0, 2, 3, 1)  # (バッチ、行、列、チャンネル)に変更\n",
    "image = image/2+0.5  # 0-1の範囲に\n",
    "\n",
    "rows = 3  # 行数\n",
    "columns = 5  # 列数\n",
    "scale = 4  # 表示スケール\n",
    "plt.figure(figsize=(scale*columns, scale*rows))\n",
    "\n",
    "for i in range(rows*columns):\n",
    "    ax = plt.subplot(rows, columns, i+1)\n",
    "    plt.imshow(image[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYb9yszSURKH"
   },
   "source": [
    "## ４Generatorの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4516,
     "status": "ok",
     "timestamp": 1668671071609,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "0qfDQ8QJolyo",
    "outputId": "ca83d213-eff2-46ca-93c5-0bba3c76dd17"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            # 画像サイズ 1x1→4x4\n",
    "            nn.ConvTranspose2d(n_noise, 512, 4, 1, 0),  # 入力のチャンネル数, 出力のチャンネル数, カーネルのサイズ、ストライド、パディング\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # 画像サイズ 4x4→8x8\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # 画像サイズ 8x8→16x16\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # 画像サイズ 16x16→32x32\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "           # 画像サイズ 32x32→64x64\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # 画像サイズ 64x64→128x128\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, n_noise, 1, 1)  # (バッチサイズ, チャンネル数, 高さ, 幅)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "generator = Generator()\n",
    "generator.cuda()  # GPU対応\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtA6l8bpD9rw"
   },
   "source": [
    "## ５Discriminatorの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668671076614,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "YKqGNtX2D97k",
    "outputId": "a8f48427-86cf-4424-fad3-0ad8b8e42c96"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            # 画像サイズ 128x128→64x64\n",
    "            nn.Conv2d(3, 32, 4, 2, 1),  # 入力のチャンネル数, 出力のチャンネル数, カーネルのサイズ\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            # 画像サイズ 64x64→32x32\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            # 画像サイズ 32x32→16x16\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            # 画像サイズ 16x16→8x8\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "           # 画像サイズ 8x8→4x4\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.2),\n",
    "            # 画像サイズ 4x4→1x1\n",
    "            nn.Conv2d(512, 1, 4, 1, 0),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, img_size, img_size)  # (バッチサイズ, チャンネル数, 高さ, 幅)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(-1, 1)  # (バッチサイズ, 出力の数)\n",
    "        return x\n",
    "\n",
    "discriminator = Discriminator()\n",
    "discriminator.cuda()  # GPU対応\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHM61pcsW6rY"
   },
   "source": [
    "## ６画像の生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 713,
     "status": "ok",
     "timestamp": 1668671152484,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "M0Waj3m0W-oo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -- 画像を生成して表示 --\n",
    "def generate_images(i):\n",
    "    # 画像の生成\n",
    "    n_rows = 4  # 行数\n",
    "    n_cols = 4  # 列数\n",
    "    noise = torch.randn(n_rows * n_cols, n_noise).cuda()\n",
    "    g_imgs = generator(noise)\n",
    "    g_imgs = g_imgs/2 + 0.5  # 0-1の範囲にする\n",
    "    g_imgs = g_imgs.cpu().detach().numpy()\n",
    "\n",
    "    img_size_spaced = img_size + 2\n",
    "    matrix_image = np.zeros((img_size_spaced*n_rows, img_size_spaced*n_cols, 3))  # 全体の画像\n",
    "\n",
    "    #  生成された画像を並べて一枚の画像にする\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            g_img = g_imgs[r*n_cols + c].transpose(1, 2, 0).reshape(img_size, img_size, 3)\n",
    "            top = r*img_size_spaced\n",
    "            left = c*img_size_spaced\n",
    "            matrix_image[top : top+img_size, left : left+img_size, :] = g_img\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(matrix_image, vmin=0.0, vmax=1.0)\n",
    "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # 軸目盛りのラベルと線を消す\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MA9y1jWPo0D"
   },
   "source": [
    "## ７正解数の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668671162885,
     "user": {
      "displayName": "Zhengcheng Qu",
      "userId": "15412233948967565620"
     },
     "user_tz": -540
    },
    "id": "0qUJa7_wP2gN"
   },
   "outputs": [],
   "source": [
    "def count_correct(y, t):\n",
    "    correct = torch.sum((torch.where(y<0.5, 0, 1) ==  t).float())\n",
    "    return correct.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XC4f8NH6U86F"
   },
   "source": [
    "## ８学習 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1b9yu4HmsZB_I_i-2TRjVyBkF785DHual"
    },
    "id": "KoOAs3rh2PJJ",
    "outputId": "853b009d-6b32-4f9f-b314-e474da9f1745"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# 平均二乗誤差\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# Adam\n",
    "optimizer_gen = optim.Adam(generator.parameters(), lr=0.001, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "optimizer_disc = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "\n",
    "# ログ\n",
    "error_record_fake = []  # 偽物画像の誤差記録\n",
    "acc_record_fake = []  # 偽物画像の精度記録\n",
    "error_record_real = []  # 本物画像の誤差記録\n",
    "acc_record_real = []  # 本物画像の精度記録\n",
    "\n",
    "# -- DCGANの学習 --\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "for i in range(epochs):\n",
    "    loss_fake = 0  # 誤差\n",
    "    correct_fake = 0  # 正解数\n",
    "    loss_real = 0\n",
    "    correct_real = 0\n",
    "    n_total = 0  # データの総数（精度の計算に使用）\n",
    "    for j, (x, t) in enumerate(train_loader):  # ミニバッチ（x,）を取り出す\n",
    "\n",
    "        n_total += x.size()[0]  # バッチサイズを累積\n",
    "\n",
    "        # ノイズから画像を生成しDiscriminatorを訓練\n",
    "        noise = torch.randn(x.size()[0], n_noise).cuda()\n",
    "        imgs_fake = generator(noise)  # 画像の生成\n",
    "        t = torch.zeros(x.size()[0], 1).cuda()  # 正解は0\n",
    "        y = discriminator(imgs_fake)\n",
    "        loss = loss_func(y, t)\n",
    "        optimizer_disc.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_disc.step()  # Discriminatorのみパラメータを更新\n",
    "        loss_fake += loss.item()\n",
    "        correct_fake += count_correct(y, t)\n",
    "\n",
    "        # 本物の画像を使ってDiscriminatorを訓練\n",
    "        imgs_real= x.cuda()\n",
    "        t = torch.ones(x.size()[0], 1).cuda()  # 正解は1\n",
    "        y = discriminator(imgs_real)\n",
    "        loss = loss_func(y, t)\n",
    "        optimizer_disc.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_disc.step()  # Discriminatorのみパラメータを更新\n",
    "        loss_real += loss.item()\n",
    "        correct_real += count_correct(y, t)\n",
    "\n",
    "        # Generatorを訓練\n",
    "        imgs_fake = generator(noise)  # 画像の生成\n",
    "        t = torch.ones(x.size()[0], 1).cuda()  # 正解は1\n",
    "        y = discriminator(imgs_fake)\n",
    "        loss = loss_func(y, t)\n",
    "        optimizer_gen.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_gen.step()  # Generatorのみパラメータを更新\n",
    "\n",
    "    loss_fake /= j+1  # 誤差\n",
    "    error_record_fake.append(loss_fake)\n",
    "    acc_fake = correct_fake / n_total  # 精度\n",
    "    acc_record_fake.append(acc_fake)\n",
    "\n",
    "    loss_real /= j+1  # 誤差\n",
    "    error_record_real.append(loss_real)\n",
    "    acc_real = correct_real / n_total  # 精度\n",
    "    acc_record_real.append(acc_real)\n",
    "\n",
    "    # 一定間隔で誤差と精度、および生成された画像を表示\n",
    "    if i % interval == 0:\n",
    "        print (\"Epochs:\", i)\n",
    "        print (\"Error_fake:\", loss_fake , \"Acc_fake:\", acc_fake)\n",
    "        print (\"Error_real:\", loss_real , \"Acc_real:\", acc_real)\n",
    "        generate_images(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvxNus-jNWk3"
   },
   "source": [
    "### 8.1誤差と正解率の推移 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWIKYIQODJ0Q"
   },
   "outputs": [],
   "source": [
    "# -- 誤差の推移 --\n",
    "plt.plot(range(len(error_record_fake)), error_record_fake, label=\"Error_fake\")\n",
    "plt.plot(range(len(error_record_real)), error_record_real, label=\"Error_real\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()\n",
    "\n",
    "# -- 正解率の推移 --\n",
    "plt.plot(range(len(acc_record_fake)), acc_record_fake, label=\"Acc_fake\")\n",
    "plt.plot(range(len(acc_record_real)), acc_record_real, label=\"Acc_real\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cr0qZ81oX3Bk"
   ],
   "name": "",
   "provenance": [
    {
     "file_id": "1sKaXLJT5XnJh7vsLmGC3l-WWjbWaE28K",
     "timestamp": 1668653195815
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
